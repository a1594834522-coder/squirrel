-- rime.lua
-- AI æ™ºèƒ½è¡¥å…¨æ’ä»¶

-- ============================================================================
-- å…¨å±€çŠ¶æ€ç®¡ç†
-- ============================================================================

-- è¾“å…¥å†å²è®°å½•ï¼ˆç”¨äº AI ä¸Šä¸‹æ–‡ï¼‰
local input_history = {}
local context_window_minutes = 10  -- æ”¹ä¸º 10 åˆ†é’Ÿ

-- AI å€™é€‰ç¼“å­˜ï¼ˆæŒ‰ Tab æ—¶è§¦å‘ AIï¼Œç¼“å­˜ç»“æœï¼‰
local ai_candidates_cache = {
    input = nil,
    candidates = nil,
    timestamp = 0
}

-- Command é”®é—®ç­”çŠ¶æ€ç®¡ç†
local qa_state = {
    mode = "none",        -- "none" | "question" | "answer"
    question = nil,       -- ä¿å­˜ç”Ÿæˆçš„é—®é¢˜
    last_input = nil,     -- ä¿å­˜è§¦å‘é—®é¢˜çš„æ‹¼éŸ³
    timestamp = 0
}

-- AI é…ç½®ï¼ˆä» schema è¯»å–ï¼‰
local ai_config = {
    enabled = true,
    -- GPT-4o-mini é…ç½®ï¼ˆç”¨äºè”æƒ³å’Œé—®é¢˜ç”Ÿæˆï¼‰
    base_url = "https://api.openai.com/v1/chat/completions",
    api_key = "YOUR_API_KEY_HERE",
    model_name = "gpt-4o-mini",
    -- Grok é…ç½®ï¼ˆç”¨äºé—®é¢˜å›ç­”ï¼‰
    grok_base_url = "https://api.x.ai/v1/chat/completions",
    grok_api_key = "YOUR_GROK_API_KEY_HERE",
    grok_model_name = "grok-4-fast",
    max_candidates = 3,
    system_prompt = [[ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡è¾“å…¥æ³•çš„è”æƒ³ä¸è¡¥å…¨åŠ©æ‰‹ï¼Œä¸»è¦ç›®æ ‡æ˜¯å¸®åŠ©ç”¨æˆ·æ›´å¿«è¾“å…¥è‡ªç„¶ã€ç®€æ´çš„çŸ­è¯­ã€‚

ä½¿ç”¨åœºæ™¯ï¼š
- ç”¨æˆ·æ­£åœ¨ç”µè„‘æˆ–æ‰‹æœºä¸Šæ‰“å­—ï¼Œä½¿ç”¨æ‹¼éŸ³è¾“å…¥æ³•ã€‚
- ä½ åªè´Ÿè´£æ ¹æ®ç”¨æˆ·çš„å†å²è¾“å…¥å’Œå½“å‰æ‹¼éŸ³ï¼Œç»™å‡ºè‹¥å¹²è”æƒ³å€™é€‰ã€‚

ä½ ä¼šå¾—åˆ°ï¼š
1. æœ€è¿‘ 10 åˆ†é’Ÿå†…ç”¨æˆ·å·²ç»è¾“å…¥çš„ä¸­æ–‡æ–‡æœ¬ï¼ˆä¸Šä¸‹æ–‡ï¼‰
2. å½“å‰æ­£åœ¨è¾“å…¥çš„æ‹¼éŸ³ä¸²ï¼ˆä¾‹å¦‚ nihaoã€wojiao ç­‰ï¼‰

ä½ çš„ä»»åŠ¡ï¼š
- æ­£ç¡®ç†è§£è¯¥æ‹¼éŸ³å¯¹åº”çš„ä¸­æ–‡è¯è¯­æˆ–çŸ­è¯­ã€‚
- ç»“åˆä¸Šä¸‹æ–‡ï¼Œè”æƒ³å‡ºç”¨æˆ·å¾ˆå¯èƒ½æƒ³ç»§ç»­è¾“å…¥çš„å†…å®¹ã€‚
- æ¯ä¸ªè”æƒ³ç»“æœéƒ½å¿…é¡»åŒ…å«è¿™ä¸ªä¸­æ–‡è¯è¯­æˆ–çŸ­è¯­ï¼ˆæˆ–å…¶è‡ªç„¶å˜ä½“ï¼‰ï¼Œå¹¶å°½é‡æ”¾åœ¨å¥å­æˆ–çŸ­è¯­çš„å¼€å¤´ã€‚
- ä¼˜å…ˆç”Ÿæˆé€‚åˆç›´æ¥ä¸Šå±çš„çŸ­è¯­æˆ–ç®€çŸ­å¥å­ï¼Œè€Œä¸æ˜¯å¾ˆé•¿çš„æ®µè½ã€‚
- ä¸¥æ ¼é¿å…è·‘é¢˜ï¼Œä¸è¦å¼•å…¥ä¸ä¸Šä¸‹æ–‡å’Œå½“å‰æ‹¼éŸ³æ— å…³çš„è¯é¢˜ã€‚

ç¤ºä¾‹æ¾„æ¸…ï¼š
- æ‹¼éŸ³ï¼šruhexiazaipython
  åº”ç†è§£ä¸ºâ€œå¦‚ä½•ä¸‹è½½ Pythonï¼ˆè½¯ä»¶æœ¬èº«ï¼‰â€ï¼Œåˆé€‚çš„è”æƒ³å¯ä»¥æ˜¯â€œå¦‚ä½•ä¸‹è½½å¹¶å®‰è£… Pythonï¼Ÿâ€ã€â€œåœ¨å“ªé‡Œå¯ä»¥ä¸‹è½½ Python å®˜æ–¹å®‰è£…åŒ…ï¼Ÿâ€ç­‰ï¼›
  ä¸è¦æ”¹å†™æˆâ€œå¦‚ä½•åœ¨ Python ä¸­å®ç°ä¸‹è½½åŠŸèƒ½â€ç­‰æ”¹å˜è¯­ä¹‰çš„è¡¨è¾¾ã€‚

è¾“å‡ºæ ¼å¼ï¼š
- ä¸¥æ ¼è¿”å› 3 è¡Œæ–‡æœ¬ï¼Œæ¯è¡Œä¸€ä¸ªå€™é€‰ã€‚
- æ¯è¡ŒåªåŒ…å«å€™é€‰å†…å®¹æœ¬èº«ï¼Œä¸è¦ä»»ä½•è¯´æ˜æ€§æ–‡å­—ã€‚
- ç¦æ­¢è¾“å‡ºä»»ä½•å½¢å¼çš„åºå·æˆ–é¡¹ç›®ç¬¦å·ï¼ˆä¾‹å¦‚ "1."ã€"â‘ "ã€"- "ã€"(1)"ã€"ã€ã€‘" ç­‰ï¼‰ï¼Œä¹Ÿä¸è¦ä½¿ç”¨ç±»ä¼¼â€œå€™é€‰1:â€â€œå»ºè®®ï¼šâ€ä¹‹ç±»çš„å‰ç¼€ã€‚
- å†…å®¹è¦è‡ªç„¶ã€å£è¯­åŒ–æˆ–ä¹¦é¢åŒ–å‡å¯ï¼Œä½†éœ€è¦é€‚åˆç›´æ¥ä½œä¸ºè¾“å…¥æ³•å€™é€‰ä¸Šå±ã€‚
- åœ¨æ»¡è¶³ä¸Šè¿°æ¡ä»¶çš„å‰æä¸‹ï¼Œæ¯ä¸ªå€™é€‰å»ºè®®æ§åˆ¶åœ¨çº¦ 8ï½20 ä¸ªæ±‰å­—ã€‚]]
}

-- ============================================================================
-- å·¥å…·å‡½æ•°
-- ============================================================================

-- è·å–å½“å‰æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
local function get_timestamp()
    return os.time()
end

-- æ¸…ç†è¿‡æœŸçš„å†å²è®°å½•
local function cleanup_history()
    local now = get_timestamp()
    local cutoff = now - (context_window_minutes * 60)

    local new_history = {}
    for _, entry in ipairs(input_history) do
        if entry.timestamp >= cutoff then
            table.insert(new_history, entry)
        end
    end
    input_history = new_history
end

-- æ·»åŠ åˆ°å†å²è®°å½•
local function add_to_history(text)
    if text and text ~= "" then
        cleanup_history()
        table.insert(input_history, {
            text = text,
            timestamp = get_timestamp()
        })

        -- é™åˆ¶å†å²è®°å½•æ•°é‡ï¼ˆæœ€å¤š100æ¡ï¼‰
        if #input_history > 100 then
            table.remove(input_history, 1)
        end
    end
end

-- è·å–å†å²ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
local function get_history_context()
    cleanup_history()

    local context_parts = {}
    for _, entry in ipairs(input_history) do
        table.insert(context_parts, entry.text)
    end

    return table.concat(context_parts, " ")
end

-- å†™å…¥è°ƒè¯•æ—¥å¿—
local function debug_log(message)
    local log_file = os.getenv("HOME") .. "/Library/Rime/ai_debug.log"
    local f = io.open(log_file, "a")
    if f then
        f:write(os.date("%Y-%m-%d %H:%M:%S") .. " - " .. message .. "\n")
        f:close()
    end
end

-- HTTP POST è¯·æ±‚ï¼ˆä½¿ç”¨ä¸´æ—¶è„šæœ¬æ–‡ä»¶ï¼‰
local function http_post(url, headers, body)
    local home = os.getenv("HOME")
    local script_file = home .. "/Library/Rime/curl_request.sh"
    local output_file = home .. "/Library/Rime/curl_output.txt"

    -- æ„å»º curl å‘½ä»¤ï¼ˆæ·»åŠ è¶…æ—¶å‚æ•°é¿å…é˜»å¡ï¼‰
    local cmd = string.format('curl -s --connect-timeout 10 --max-time 30 -X POST "%s"', url)

    -- æ·»åŠ  headers
    for key, value in pairs(headers) do
        cmd = cmd .. string.format(' -H "%s: %s"', key, value)
    end

    -- æ·»åŠ  body - ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    local body_file = home .. "/Library/Rime/curl_body.json"
    local f = io.open(body_file, "w")
    if not f then
        debug_log("ERROR: Cannot create body file")
        return nil, "Cannot create body file"
    end
    f:write(body)
    f:close()

    cmd = cmd .. string.format(' -d @"%s" > "%s" 2>&1', body_file, output_file)

    -- å†™å…¥è„šæœ¬æ–‡ä»¶
    local script = io.open(script_file, "w")
    if not script then
        debug_log("ERROR: Cannot create script file")
        return nil, "Cannot create script file"
    end
    script:write("#!/bin/bash\n")
    script:write(cmd .. "\n")
    script:close()

    -- è®¾ç½®æ‰§è¡Œæƒé™å¹¶æ‰§è¡Œ
    os.execute(string.format('chmod +x "%s"', script_file))

    debug_log("Executing: " .. cmd)
    local exit_code = os.execute(string.format('"%s"', script_file))
    debug_log("Exit code: " .. tostring(exit_code))

    -- è¯»å–è¾“å‡º
    local output = io.open(output_file, "r")
    if not output then
        debug_log("ERROR: Cannot read output file")
        return nil, "Cannot read output file"
    end

    local result = output:read("*a")
    output:close()

    -- è®°å½•å“åº”
    debug_log("Response: " .. (result or "nil"))

    -- æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    os.remove(script_file)
    os.remove(body_file)
    os.remove(output_file)

    return result, nil
end

-- è§£æ JSON å“åº”ï¼ˆæ”¹è¿›çš„å®ç°ï¼‰
local function parse_json_response(json_str)
    if not json_str or json_str == "" then
        debug_log("ERROR: Empty JSON response")
        return nil
    end

    -- è®°å½•åŸå§‹å“åº”ç”¨äºè°ƒè¯•
    debug_log("Parsing JSON, length: " .. #json_str)

    -- å°è¯•å¤šç§æ–¹å¼æå– content
    -- æ–¹æ³•1: åŒ¹é…å¸¦è½¬ä¹‰çš„ content
    local content = json_str:match('"content"%s*:%s*"(.-)"[,%s]*"role"')

    if not content then
        -- æ–¹æ³•2: æ›´å®½æ¾çš„åŒ¹é…
        content = json_str:match('"content"%s*:%s*"(.-)"')
    end

    if not content then
        -- æ–¹æ³•3: å¤„ç†å¯èƒ½çš„å¤šè¡Œå†…å®¹
        content = json_str:match('"content"%s*:%s*"(.+)"[,%}]')
    end

    if content then
        -- åè½¬ä¹‰å¸¸è§çš„ JSON è½¬ä¹‰å­—ç¬¦
        content = content:gsub('\\n', '\n')
        content = content:gsub('\\r', '\r')
        content = content:gsub('\\t', '\t')
        content = content:gsub('\\"', '"')
        content = content:gsub('\\\\', '\\')
        content = content:gsub('\\/', '/')

        -- å»é™¤é¦–å°¾ç©ºç™½
        content = content:gsub("^%s*", ""):gsub("%s*$", "")

        debug_log("Parsed content length: " .. #content)
        return content
    end

    debug_log("ERROR: Failed to parse content from JSON")
    return nil
end

-- ç”Ÿæˆæœ‰ä»·å€¼çš„é—®é¢˜
local function generate_question(pinyin)
    debug_log("=== Generating Questions ===")
    debug_log("Pinyin: " .. pinyin)

    local system_prompt = [[ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡è¾“å…¥æ³•ä¸­çš„â€œå‡ºé¢˜åŠ©æ‰‹â€ï¼Œæ ¹æ®ç”¨æˆ·æ­£åœ¨è¾“å…¥çš„æ‹¼éŸ³ï¼Œç»™å‡ºå‡ ä¸ªå€¼å¾—æ€è€ƒæˆ–æ£€ç´¢çš„ä¸­æ–‡é—®é¢˜ã€‚

ä½¿ç”¨åœºæ™¯ï¼š
- ç”¨æˆ·è¾“å…¥ä¸€ä¸ªè¯è¯­æˆ–çŸ­è¯­çš„æ‹¼éŸ³ï¼Œä½ éœ€è¦ç†è§£å®ƒæœ€å¸¸è§ã€æœ€åˆç†çš„å«ä¹‰ã€‚
- ä½ è¦å›´ç»•è¿™ä¸ªå«ä¹‰ï¼Œç”Ÿæˆè‹¥å¹²æœ‰ä»·å€¼ã€è‡ªç„¶çš„ä¸­æ–‡é—®å¥ï¼Œæ–¹ä¾¿ç”¨æˆ·ç»§ç»­è¾“å…¥æˆ–æœç´¢ã€‚

å¤„ç†åŸåˆ™ï¼š
1. å…ˆåˆ¤æ–­æ‹¼éŸ³æœ€å¸¸è§ã€æœ€åˆç†çš„ä¸­æ–‡å«ä¹‰ï¼Œå¯ä»¥æ˜¯äººåã€åœ°åã€ä¸“æœ‰åè¯ã€æŠ€æœ¯æœ¯è¯­æˆ–æ™®é€šè¯è¯­ã€‚
2. å¦‚æœå­˜åœ¨å¤šç§åŒéŸ³å«ä¹‰ï¼Œä¼˜å…ˆé€‰æ‹©æ—¥å¸¸ä½¿ç”¨ä¸­æœ€å¸¸è§ã€æœ€åˆç†çš„é‚£ä¸ªï¼Œä¸è¦ç”Ÿé€ å†·åƒ»è§£é‡Šã€‚
3. å›´ç»•é€‰å®šå«ä¹‰ï¼Œä»ä¸åŒè§’åº¦è®¾è®¡é—®é¢˜ï¼Œä¾‹å¦‚èƒŒæ™¯ä¿¡æ¯ã€ä½¿ç”¨æ–¹æ³•ã€å½±å“ã€ä¼˜ç¼ºç‚¹ç­‰ã€‚
4. é—®å¥è¦å…·ä½“ã€æœ‰ä¿¡æ¯é‡ï¼Œé¿å…â€œæ˜¯ä»€ä¹ˆï¼Ÿâ€è¿™ç±»è¿‡äºç©ºæ³›çš„æé—®ã€‚

æ³¨æ„äº‹é¡¹ï¼š
- å¯ä»¥è¯†åˆ«å¹¶æ­£ç¡®ä¹¦å†™åäººã€å“ç‰Œã€æŠ€æœ¯æœ¯è¯­ç­‰ï¼Œä½†ä¸è¦è¿‡åº¦å¼ºè¡Œå¾€è¿™äº›æ–¹å‘çŒœã€‚
- ç»“åˆå¸¸è§æ­é…å’Œä½¿ç”¨åœºæ™¯ï¼Œä¿è¯é—®å¥è‡ªç„¶ã€ç¬¦åˆä¸­æ–‡è¡¨è¾¾ä¹ æƒ¯ã€‚
- ä¸è¦ç®€å•åœ°æŠŠæ‹¼éŸ³é€å­—æ‹†å¼€è§£é‡Šï¼Œè¦ç†è§£å®ƒåœ¨çœŸå®è¯­å¢ƒä¸‹æœ€å¯èƒ½æŒ‡ä»£çš„ä¸œè¥¿ã€‚

ç‰¹åˆ«ç¤ºä¾‹ï¼š
- å½“æ‹¼éŸ³æ˜¯ ruhexiazaipython æ—¶ï¼Œåº”ç†è§£ä¸ºâ€œå¦‚ä½•ä¸‹è½½ Pythonï¼ˆè½¯ä»¶æœ¬èº«ï¼‰â€ï¼Œè€Œä¸æ˜¯â€œå¦‚ä½•åœ¨ Python ä¸­å®ç°ä¸‹è½½åŠŸèƒ½â€ã€‚åœ¨ç±»ä¼¼ç»“æ„ä¸‹ï¼Œä¼˜å…ˆä¿æŒâ€œå¦‚ä½•ä¸‹è½½ Xâ€è¿™ç§åŠ¨å®¾å…³ç³»çš„è¯­ä¹‰ï¼Œä¸è¦æ”¹å†™æˆâ€œåœ¨ X ä¸­å¦‚ä½•å®ç°ä¸‹è½½â€ã€‚ 

è¾“å‡ºæ ¼å¼ï¼š
- ä¸¥æ ¼è¿”å› 3 è¡Œä¸­æ–‡ï¼Œæ¯è¡Œä¸€ä¸ªç‹¬ç«‹çš„é—®å¥ã€‚
- ä¸è¦åœ¨è¡Œé¦–æ·»åŠ ä»»ä½•åºå·ã€é¡¹ç›®ç¬¦å·æˆ–å…¶å®ƒå‰ç¼€ï¼ˆä¾‹å¦‚ "1."ã€"â‘ "ã€"- "ã€"(1)"ã€"ã€ã€‘" ç­‰ï¼‰ï¼Œä¹Ÿä¸è¦ä½¿ç”¨ç±»ä¼¼â€œé—®é¢˜1:â€â€œé—®é¢˜ï¼šâ€ä¹‹ç±»çš„æ–‡å­—è¯´æ˜ã€‚
- æ¯ä¸ªé—®é¢˜æ˜¯å®Œæ•´çš„å¥å­ï¼Œä»¥é—®å·ç»“å°¾ï¼Œä¿¡æ¯å°½é‡å…·ä½“ã€æœ‰ä»·å€¼ã€‚]]

    local user_prompt = string.format(
        "æ‹¼éŸ³ï¼š%s\n\nè¯·å…ˆåˆ¤æ–­è¿™ä¸ªæ‹¼éŸ³åœ¨æ—¥å¸¸è¯­å¢ƒä¸‹æœ€å¸¸è§ã€æœ€åˆç†çš„ä¸­æ–‡å«ä¹‰ï¼Œç„¶åå›´ç»•è¿™ä¸ªå«ä¹‰ç”Ÿæˆ 3 ä¸ªæœ‰ä»·å€¼çš„ä¸­æ–‡é—®é¢˜ã€‚é—®é¢˜è¦å…·ä½“ã€æœ‰ä¿¡æ¯é‡ï¼Œå¹¶ä»¥é—®å·ç»“å°¾ã€‚ä¸¥æ ¼æŒ‰ 3 è¡Œè¾“å‡ºï¼Œæ¯è¡Œä¸€ä¸ªé—®é¢˜ï¼Œä¸è¦åŠ ä»»ä½•åºå·ã€é¡¹ç›®ç¬¦å·æˆ–å…¶å®ƒå‰ç¼€ã€‚",
        pinyin
    )

    local request_body = string.format([[{
        "model": "%s",
        "messages": [
            {"role": "system", "content": "%s"},
            {"role": "user", "content": "%s"}
        ],
        "temperature": 0.1,
        "max_tokens": 300
    }]],
        ai_config.model_name,
        system_prompt:gsub('"', '\\"'):gsub('\n', '\\n'),
        user_prompt:gsub('"', '\\"'):gsub('\n', '\\n')
    )

    local headers = {
        ["Content-Type"] = "application/json",
        ["Authorization"] = "Bearer " .. ai_config.api_key
    }

    local response, err = http_post(ai_config.base_url, headers, request_body)
    if err or not response then
        debug_log("ERROR: Failed to generate questions")
        return nil
    end

    local content = parse_json_response(response)
    if not content or content == "" then
        debug_log("ERROR: Empty content from parse_json_response")
        return nil
    end

    debug_log("Raw question content: " .. content:sub(1, 200))

    -- åˆ†å‰²æˆå¤šä¸ªé—®é¢˜
    local questions = {}
    for line in content:gmatch("[^\n]+") do
        line = line:gsub("^%s*", ""):gsub("%s*$", "")
        -- è¿‡æ»¤æ‰ç©ºè¡Œã€å¤ªçŸ­çš„è¡Œå’Œéä¸­æ–‡å†…å®¹
        if line ~= "" and #line >= 3 and line:match("[\228-\233]") then
            table.insert(questions, line)
            debug_log("Question " .. #questions .. ": " .. line)
            if #questions >= 3 then
                break
            end
        end
    end

    if #questions == 0 then
        debug_log("ERROR: No valid questions generated")
        return nil
    end

    debug_log("Generated " .. #questions .. " questions")
    return questions
end

-- å›ç­”é—®é¢˜
local function answer_question(question)
    debug_log("=== Answering Question ===")
    debug_log("Question: " .. question)

    local system_prompt = [[ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€å‹å¥½çš„ä¸­æ–‡é—®ç­”åŠ©æ‰‹ï¼Œç”¨äºåœ¨è¾“å…¥æ³•ä¸­ä¸ºç”¨æˆ·æä¾›ç®€æ´ä½†æœ‰ç”¨çš„ç­”æ¡ˆã€‚

å›ç­”ä»»åŠ¡ï¼š
- ç”¨æˆ·ä¼šç»™å‡ºä¸€ä¸ªä¸­æ–‡é—®é¢˜ï¼Œä½ éœ€è¦ç»™å‡ºä¸€ä¸ªç›´æ¥ã€æ¸…æ™°çš„å›ç­”ã€‚
- é‡ç‚¹æ˜¯å¿«é€Ÿä¼ è¾¾æ ¸å¿ƒä¿¡æ¯ï¼Œè€Œä¸æ˜¯å†™é•¿ç¯‡å¤§è®ºã€‚

å›ç­”åŸåˆ™ï¼š
1. å‡†ç¡®æ€§ï¼šå°½é‡æä¾›çœŸå®ã€å¯é çš„ä¿¡æ¯ï¼›ä¸ç¡®å®šæ—¶å¯ç®€è¦è¯´æ˜ä¸ç¡®å®šæ€§ã€‚
2. å®Œæ•´æ€§ï¼šè¦†ç›–é—®é¢˜ä¸­æœ€é‡è¦çš„ 1â€“3 ä¸ªä¿¡æ¯ç‚¹ã€‚
3. ç®€æ´æ€§ï¼šç”¨ 1â€“2 å¥è¯è¯´æ˜ç™½ï¼Œé¿å…å†—é•¿è§£é‡Šã€‚
4. å®ç”¨æ€§ï¼šä¼˜å…ˆç»™å‡ºå¯¹ç”¨æˆ·æœ‰å¸®åŠ©ã€å¯æ‰§è¡Œæˆ–å¯ç†è§£çš„å†…å®¹ã€‚

è¾“å‡ºæ ¼å¼ï¼š
- è¿”å›ä¸€ä¸ªè¿ç»­çš„ä¸­æ–‡å›ç­”æ®µè½ï¼ˆé€šå¸¸ 1â€“2 å¥è¯ï¼‰ã€‚
- ä¸è¦ä½¿ç”¨ä»»ä½•åºå·ã€åˆ—è¡¨ç¬¦å·æˆ–å¤šè¡Œç»“æ„ã€‚
- ç›´æ¥è¾“å‡ºç­”æ¡ˆå†…å®¹ï¼Œä¸è¦è§£é‡Šä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œä¸è¦é‡å¤â€œé—®é¢˜æ˜¯â€¦â€¦â€ï¼Œä¸è¦æ·»åŠ â€œå›ç­”ï¼šâ€â€œå›ç­”1:â€ ç­‰å‰ç¼€ã€‚]]

    local user_prompt = string.format(
        "é—®é¢˜ï¼š%s\n\nè¯·ç”¨ 1â€“2 å¥è¯ç»™å‡ºä¸€ä¸ªå‡†ç¡®ã€ç®€æ´ã€ä¿¡æ¯é‡è¶³å¤Ÿçš„å›ç­”ã€‚åªè¾“å‡ºç­”æ¡ˆæœ¬èº«ï¼Œä¸è¦é‡å¤é—®é¢˜ï¼Œä¹Ÿä¸è¦æ·»åŠ ä»»ä½•åºå·ã€é¡¹ç›®ç¬¦å·æˆ–åˆ†ç‚¹è¯´æ˜ã€‚",
        question
    )

    local request_body = string.format([[{
        "model": "%s",
        "messages": [
            {"role": "system", "content": "%s"},
            {"role": "user", "content": "%s"}
        ],
        "temperature": 0.7,
        "max_tokens": 500
    }]],
        ai_config.model_name,
        system_prompt:gsub('"', '\\"'):gsub('\n', '\\n'),
        user_prompt:gsub('"', '\\"'):gsub('\n', '\\n')
    )

    local headers = {
        ["Content-Type"] = "application/json",
        ["Authorization"] = "Bearer " .. ai_config.api_key
    }

    local response, err = http_post(ai_config.base_url, headers, request_body)
    if err or not response then
        debug_log("ERROR: Failed to answer question")
        return nil
    end

    local content = parse_json_response(response)
    if not content or content == "" then
        debug_log("ERROR: Empty content from parse_json_response")
        return nil
    end

    debug_log("Raw answer content: " .. content:sub(1, 200))  -- è®°å½•å‰200ä¸ªå­—ç¬¦

    -- æ¸…ç†å›ç­”å†…å®¹ï¼Œå»é™¤å¤šä½™çš„ç©ºç™½å’Œæ¢è¡Œ
    content = content:gsub("^%s*", ""):gsub("%s*$", "")

    -- æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å†…å®¹
    if not content:match("[\228-\233]") then
        debug_log("ERROR: No Chinese content in answer")
        return nil
    end

    debug_log("Complete answer: " .. content)

    -- è¿”å›å•ä¸ªå®Œæ•´ç­”æ¡ˆï¼ˆä½œä¸ºæ•°ç»„ï¼Œä¿æŒæ¥å£ä¸€è‡´ï¼‰
    return {content}
end

-- è°ƒç”¨ AI API
local function call_ai_api(current_pinyin, history_context)
    debug_log("=== AI API Call Start ===")
    debug_log("Current pinyin input: " .. current_pinyin)
    debug_log("History context: " .. history_context)

    if not ai_config.enabled then
        debug_log("AI disabled")
        return nil
    end

    -- æ„å»ºä¼˜åŒ–çš„æç¤ºè¯
    local user_prompt
    if history_context == "" then
        -- æ²¡æœ‰å†å²è®°å½•æ—¶
        user_prompt = string.format(
            "æ‹¼éŸ³ï¼š%s\n\nè¯·æ ¹æ®è¯¥æ‹¼éŸ³å¯¹åº”çš„ä¸­æ–‡è¯è¯­ï¼Œç”Ÿæˆ 3 ä¸ªè”æƒ³å€™é€‰ã€‚æ¯ä¸ªå€™é€‰å¿…é¡»åŒ…å«è¯¥ä¸­æ–‡è¯è¯­ï¼ˆæˆ–å…¶è‡ªç„¶å˜ä½“ï¼‰ï¼Œå¹¶å°½é‡æ”¾åœ¨å¼€å¤´ï¼›å€™é€‰åº”ä¸ºç®€çŸ­çš„çŸ­è¯­æˆ–çŸ­å¥ï¼Œä¸è¦å¤ªé•¿ã€‚ä¸¥æ ¼æŒ‰ 3 è¡Œè¾“å‡ºï¼Œæ¯è¡Œä¸€ä¸ªå€™é€‰ï¼Œç¦æ­¢ä»»ä½•åºå·ã€é¡¹ç›®ç¬¦å·æˆ–è§£é‡Šã€‚",
            current_pinyin
        )
    else
        -- æœ‰å†å²è®°å½•æ—¶
        user_prompt = string.format(
            "ã€ä¸Šä¸‹æ–‡ã€‘\n%s\n\nã€æ‹¼éŸ³ã€‘\n%s\n\nè¯·åŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨è¯¥æ‹¼éŸ³å¯¹åº”çš„ä¸­æ–‡è¯è¯­ï¼Œç”Ÿæˆ 3 ä¸ªå¯èƒ½çš„ç»­å†™å€™é€‰ã€‚æ¯ä¸ªå€™é€‰å¿…é¡»åŒ…å«è¯¥ä¸­æ–‡è¯è¯­ï¼ˆæˆ–å…¶è‡ªç„¶å˜ä½“ï¼‰ï¼Œå¹¶å°½é‡æ”¾åœ¨çŸ­è¯­æˆ–å¥å­çš„å¼€å¤´ï¼›å€™é€‰åº”ä¸ºç®€çŸ­çš„çŸ­è¯­æˆ–çŸ­å¥ï¼Œç´§æ‰£ä¸Šä¸‹æ–‡å«ä¹‰ï¼Œä¸è¦è·‘é¢˜ã€‚ä¸¥æ ¼æŒ‰ 3 è¡Œè¾“å‡ºï¼Œæ¯è¡Œä¸€ä¸ªå€™é€‰ï¼Œç¦æ­¢ä»»ä½•åºå·ã€é¡¹ç›®ç¬¦å·æˆ–è§£é‡Šã€‚",
            history_context,
            current_pinyin
        )
    end

    -- æ„å»ºè¯·æ±‚ä½“
    local request_body = string.format([[{
        "model": "%s",
        "messages": [
            {"role": "system", "content": "%s"},
            {"role": "user", "content": "%s"}
        ],
        "temperature": 0.9,
        "max_tokens": 200
    }]],
        ai_config.model_name,
        ai_config.system_prompt:gsub('"', '\\"'):gsub('\n', '\\n'),
        user_prompt:gsub('"', '\\"'):gsub('\n', '\\n')
    )

    debug_log("Request body: " .. request_body)

    -- å‘é€è¯·æ±‚
    local headers = {
        ["Content-Type"] = "application/json",
        ["Authorization"] = "Bearer " .. ai_config.api_key
    }

    local response, err = http_post(ai_config.base_url, headers, request_body)
    if err or not response then
        debug_log("ERROR: HTTP request failed - " .. (err or "no response"))
        return nil
    end

    -- è§£æå“åº”
    local content = parse_json_response(response)
    if not content then
        debug_log("ERROR: Failed to parse JSON response")
        return nil
    end

    debug_log("Parsed content: " .. content)

    -- åˆ†å‰²æˆå¤šä¸ªå€™é€‰ï¼Œå¹¶æ¸…ç†ç©ºç™½å­—ç¬¦
    local candidates = {}
    for line in content:gmatch("[^\n]+") do
        -- å»é™¤é¦–å°¾ç©ºç™½å’Œç‰¹æ®Šå­—ç¬¦
        line = line:gsub("^%s*", ""):gsub("%s*$", "")
        -- è¿‡æ»¤æ‰ç©ºè¡Œå’Œéä¸­æ–‡å†…å®¹ï¼ˆä¿ç•™ä¸­æ–‡ã€æ ‡ç‚¹ç¬¦å·ï¼‰
        if line ~= "" and line:match("[\228-\233]") then  -- ç®€å•çš„ä¸­æ–‡å­—ç¬¦æ£€æµ‹
            table.insert(candidates, line)
            debug_log("Candidate " .. #candidates .. ": " .. line)
            if #candidates >= ai_config.max_candidates then
                break
            end
        end
    end

    debug_log("Total candidates: " .. #candidates)
    debug_log("=== AI API Call End ===")

    return candidates
end

-- ============================================================================
-- Rime Processorï¼ˆæŒ‰é”®å¤„ç†ï¼‰
-- ============================================================================

function ai_completion_processor(key, env)
    local engine = env.engine
    local context = engine.context

    -- æ£€æµ‹æŒ‰é”® - ä½¿ç”¨ key:repr() å‡½æ•°è°ƒç”¨
    local key_repr = key:repr()
    local input = context.input

    -- å¤„ç† Command é”®
    -- macOS çš„ Command é”®è¢«è¯†åˆ«ä¸º Super+Super_L æˆ– Super+Super_R
    if key_repr == "Super+Super_L" or key_repr == "Super+Super_R" or
       key_repr == "Super_L" or key_repr == "Super_R" then
        if input and input ~= "" then
            debug_log("Command pressed with input: " .. input)

            local now = get_timestamp()

            -- æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€æ¬¡è¾“å…¥ï¼ˆ30ç§’å†…ï¼‰- å»¶é•¿æ—¶é—´ä»¥ä¾¿ç”¨æˆ·é€‰æ‹©
            local is_same_session = (qa_state.last_input == input and (now - qa_state.timestamp) < 30)

            debug_log("QA State - mode: " .. qa_state.mode .. ", is_same_session: " .. tostring(is_same_session))
            debug_log("Time diff: " .. tostring(now - qa_state.timestamp) .. " seconds")

            if qa_state.mode == "none" or not is_same_session then
                -- ç¬¬ä¸€æ¬¡æŒ‰ Commandï¼šç”Ÿæˆ3ä¸ªæœ‰ä»·å€¼çš„é—®é¢˜
                debug_log("Generating valuable questions...")
                local questions = generate_question(input)

                if questions and #questions > 0 then
                    -- ä¿å­˜çŠ¶æ€
                    qa_state.mode = "question"
                    qa_state.question = questions[1]  -- ä¿å­˜ç¬¬ä¸€ä¸ªé—®é¢˜ç”¨äºå›ç­”
                    qa_state.last_input = input
                    qa_state.timestamp = now

                    -- ç¼“å­˜3ä¸ªé—®é¢˜ä½œä¸ºå€™é€‰
                    ai_candidates_cache.input = input
                    ai_candidates_cache.candidates = questions
                    ai_candidates_cache.timestamp = now

                    context:refresh_non_confirmed_composition()
                    return 1  -- kAccepted
                end

            elseif qa_state.mode == "question" and is_same_session then
                -- ç¬¬äºŒæ¬¡æŒ‰ Commandï¼šå›ç­”ç”¨æˆ·é€‰ä¸­çš„é—®é¢˜
                debug_log("Second Command press - answering question")

                -- å°è¯•è·å–å½“å‰é€‰ä¸­çš„å€™é€‰
                local composition = context.composition
                local segment = composition:back()
                local selected_question = nil

                if segment then
                    local selected_index = segment.selected_index
                    debug_log("Selected index from segment: " .. tostring(selected_index))
                    debug_log("Cache candidates count: " .. tostring(ai_candidates_cache.candidates and #ai_candidates_cache.candidates or "nil"))

                    if ai_candidates_cache.candidates then
                        for i, q in ipairs(ai_candidates_cache.candidates) do
                            debug_log("Cached question [" .. i .. "]: " .. q)
                        end
                    end

                    -- ä»ç¼“å­˜ä¸­è·å–å¯¹åº”çš„é—®é¢˜
                    if ai_candidates_cache.candidates and selected_index >= 0 and selected_index < #ai_candidates_cache.candidates then
                        selected_question = ai_candidates_cache.candidates[selected_index + 1]
                        debug_log("Selected question from cache: " .. selected_question)
                    else
                        debug_log("Condition failed - candidates: " .. tostring(ai_candidates_cache.candidates ~= nil) ..
                                  ", index >= 0: " .. tostring(selected_index >= 0) ..
                                  ", index < count: " .. tostring(selected_index < #ai_candidates_cache.candidates))
                    end
                else
                    debug_log("No segment available")
                end

                -- å¦‚æœæ²¡æœ‰è·å–åˆ°é€‰ä¸­çš„é—®é¢˜ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªé—®é¢˜ä½œä¸ºé»˜è®¤
                if not selected_question then
                    selected_question = qa_state.question
                    debug_log("Using default (first) question: " .. selected_question)
                end

                debug_log("About to call answer_question with: " .. selected_question)
                local answers = answer_question(selected_question)
                debug_log("answer_question returned: " .. tostring(answers and #answers or "nil"))

                if answers and #answers > 0 then
                    -- ç¼“å­˜ç­”æ¡ˆä½œä¸ºå€™é€‰
                    ai_candidates_cache.input = input
                    ai_candidates_cache.candidates = answers
                    ai_candidates_cache.timestamp = now

                    -- é‡ç½®çŠ¶æ€
                    qa_state.mode = "none"
                    qa_state.question = nil

                    context:refresh_non_confirmed_composition()
                    return 1  -- kAccepted
                else
                    debug_log("ERROR: Failed to get answers or answers is empty")
                end
            end
        end
    end

    -- å¤„ç† Tab é”®
    if key_repr == "Tab" or key.keycode == 0xff09 then
        if input and input ~= "" then
            debug_log("Tab pressed with input: " .. input)

            -- é‡ç½®é—®ç­”çŠ¶æ€
            qa_state.mode = "none"
            qa_state.question = nil

            -- è·å–å†å²ä¸Šä¸‹æ–‡
            local history = get_history_context()

            -- è°ƒç”¨ AI API
            local candidates = call_ai_api(input, history)

            if candidates and #candidates > 0 then
                -- ç¼“å­˜ AI å€™é€‰ç»“æœ
                ai_candidates_cache.input = input
                ai_candidates_cache.candidates = candidates
                ai_candidates_cache.timestamp = get_timestamp()

                debug_log("AI candidates cached: " .. #candidates .. " items")

                -- åˆ·æ–°å€™é€‰åˆ—è¡¨ï¼Œè®© translator æ˜¾ç¤º AI å€™é€‰
                context:refresh_non_confirmed_composition()

                return 1  -- kAccepted - é˜»æ­¢ Tab çš„é»˜è®¤è¡Œä¸º
            else
                debug_log("AI call returned no candidates")
                -- ä¸åšä»»ä½•æ“ä½œï¼Œè®© Tab é”®æ­£å¸¸å·¥ä½œ
                return 2  -- kNoop
            end
        end
    end

    return 2  -- kNoop
end

-- ============================================================================
-- Rime Translatorï¼ˆç”Ÿæˆå€™é€‰è¯ï¼‰
-- ============================================================================

function ai_completion_translator(input, seg, env)
    -- æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„ AI å€™é€‰
    if not ai_candidates_cache.candidates then
        return
    end

    -- æ£€æŸ¥ç¼“å­˜æ˜¯å¦åŒ¹é…å½“å‰è¾“å…¥
    if ai_candidates_cache.input ~= input then
        return
    end

    -- æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸï¼ˆ30ç§’ï¼‰- ç»™ç”¨æˆ·è¶³å¤Ÿæ—¶é—´é€‰æ‹©
    local now = get_timestamp()
    if now - ai_candidates_cache.timestamp > 30 then
        ai_candidates_cache.candidates = nil
        return
    end

    debug_log("Generating AI candidates for: " .. input)

    -- æ ¹æ®é—®ç­”çŠ¶æ€å†³å®šæ˜¾ç¤ºçš„æ ‡è®°
    local comment_label
    if qa_state.mode == "question" then
        comment_label = "â“ é—®é¢˜"
    elseif qa_state.mode == "none" and qa_state.question then
        comment_label = "ğŸ’¡ å›ç­”"
    else
        comment_label = "ğŸ¤– AI"
    end

    -- ç”Ÿæˆ AI å€™é€‰é¡¹
    for i, text in ipairs(ai_candidates_cache.candidates) do
        local cand = Candidate("ai_completion", seg.start, seg._end, text, comment_label)
        cand.quality = 1000 + i  -- é«˜ä¼˜å…ˆçº§ï¼Œæ˜¾ç¤ºåœ¨æœ€å‰é¢
        yield(cand)
        debug_log("Yielded candidate: " .. text)
    end

    -- ä¸è¦ç«‹å³æ¸…ç©ºç¼“å­˜ï¼Œä¿ç•™ç¼“å­˜ä»¥ä¾¿ç¬¬äºŒæ¬¡ Command æ—¶ä½¿ç”¨
    -- ç¼“å­˜ä¼šåœ¨è¿‡æœŸæ—¶è‡ªåŠ¨æ¸…ç©ºï¼ˆ30ç§’ï¼‰æˆ–åœ¨æ–°çš„è¾“å…¥æ—¶è¢«è¦†ç›–
end

-- ============================================================================
-- åˆå§‹åŒ–å’Œæäº¤é’©å­
-- ============================================================================

-- å…¨å±€å˜é‡ï¼šä¿å­˜ä¸Šä¸€æ¬¡çš„å€™é€‰åˆ—è¡¨
local last_candidates = {}

-- ç®€åŒ–çš„å†å²è®°å½•æ•è·ï¼šè®°å½•æ‰€æœ‰å€™é€‰ï¼Œåœ¨æäº¤æ—¶æŸ¥æ‰¾
function ai_history_filter(input, env)
    -- æ¸…ç©ºä¸Šæ¬¡çš„å€™é€‰åˆ—è¡¨
    last_candidates = {}

    -- æ”¶é›†æ‰€æœ‰å€™é€‰
    for cand in input:iter() do
        -- ä¿å­˜å€™é€‰æ–‡æœ¬ï¼ˆç”¨äºåç»­åŒ¹é…ï¼‰
        table.insert(last_candidates, cand.text)
        yield(cand)
    end
end

-- ä½¿ç”¨ processor åœ¨æäº¤å‰æ•è·æ–‡æœ¬
function ai_history_processor(key, env)
    -- ç®€å•æµ‹è¯•ï¼šè®°å½•æ‰€æœ‰æŒ‰é”®
    local success, err = pcall(function()
        -- key:repr() æ˜¯å‡½æ•°è°ƒç”¨ï¼Œä¸æ˜¯å±æ€§
        local key_repr = key:repr()
        debug_log("ai_history_processor called, key: " .. tostring(key_repr))

        local engine = env.engine
        local context = engine.context

        -- æ£€æµ‹æäº¤é”®ï¼ˆç©ºæ ¼ã€å›è½¦ã€æ•°å­—é”®1-9ï¼‰
        local is_space = (key_repr == "space")
        local is_return = (key_repr == "Return")
        local is_number = (key_repr >= "1" and key_repr <= "9")
        local is_commit_key = is_space or is_return or is_number

        if is_commit_key and #last_candidates > 0 then
            debug_log("Commit key detected, candidates: " .. #last_candidates)

            -- ç©ºæ ¼é”®é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå€™é€‰ï¼ˆç´¢å¼•0ï¼‰
            local selected_index = 0

            -- æ•°å­—é”®å¯¹åº”ç›¸åº”ç´¢å¼•
            if is_number then
                selected_index = tonumber(key_repr) - 1
            end

            -- ä»å€™é€‰åˆ—è¡¨ä¸­è·å–å¯¹åº”çš„æ–‡æœ¬
            if selected_index >= 0 and selected_index < #last_candidates then
                local text = last_candidates[selected_index + 1]
                if text and text ~= "" then
                    debug_log("Committing: " .. text)
                    add_to_history(text)
                end
            end
        end
    end)

    if not success then
        debug_log("ERROR in ai_history_processor: " .. tostring(err))
    end

    return 2  -- kNoop - è®©å…¶ä»– processor ç»§ç»­å¤„ç†
end
